{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2 \n",
    "\n",
    "try:\n",
    "    from urllib import urlretrieve as urlretrieve\n",
    "except ImportError:\n",
    "    from urllib.request import urlretrieve as urlretrieve    \n",
    "\n",
    "import os\n",
    "\n",
    "#import matplotlib as plt\n",
    "import pylab as pl\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI1_PUI2018.pdf')\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI2_PUI2018.pdf')\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI3_PUI2018.pdf')\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI4_PUI2018.pdf')\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI5_PUI2018.pdf')\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI7_PUI2018.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function downloads the pdf file, moves it into the PUIdata and reads it into a dataframe\n",
    "def getPdfUrl(url,pdfFile):\n",
    "    #csvFile = 'file.csv'\n",
    "    urlretrieve(url, pdfFile)\n",
    "    os.system(\"mv \" + pdfFile + ' ' + os.getenv(\"PUIDATA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.geeksforgeeks.org/working-with-pdf-files-in-python/\n",
    "\n",
    "def extractText(pdfFilePath):\n",
    "    # creating a pdf file object \n",
    "    pdfFileObj = open(pdfFilePath, 'rb') \n",
    "\n",
    "    # creating a pdf reader object \n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "  \n",
    "    # printing number of pages in pdf file \n",
    "    n = pdfReader.numPages\n",
    "\n",
    "    text = \"\"\n",
    "    for i in range(n):\n",
    "        # creating a page object \n",
    "        pageObj = pdfReader.getPage(i)\n",
    "    \n",
    "        # extracting text from page \n",
    "        text += pageObj.extractText()\n",
    " \n",
    "    # closing the pdf file object \n",
    "    pdfFileObj.close() \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = ['UI'+str(i) for i in range(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "AllText = ''\n",
    "for i in range(len(url)):\n",
    "    getPdfUrl(url[i],fileNames[i])\n",
    "    pdfFilePath = os.getenv('PUIDATA') + '/' + fileNames[i]\n",
    "    txt = extractText(pdfFilePath)\n",
    "    texts.append(txt)\n",
    "    AllText += txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # replace '--' with a space ' '\n",
    "    doc = doc.replace('--', ' ')\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['urban', 'informatics', 'fall', 'dr', 'federica']\n",
      "Total Tokens: 11277\n",
      "Unique Tokens: 1966\n"
     ]
    }
   ],
   "source": [
    "# clean document\n",
    "doc = AllText\n",
    "tokens = clean_doc(doc)\n",
    "print(tokens[:5])\n",
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 11226\n"
     ]
    }
   ],
   "source": [
    "# organize into sequences of tokens\n",
    "length = 50 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "    # select sequence of tokens\n",
    "    seq = tokens[i-length:i]\n",
    "    # convert into a line\n",
    "    line = ' '.join(seq)\n",
    "    # store\n",
    "    sequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sequences to file\n",
    "out_filename = 'pui_sequences.txt'\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# load\n",
    "in_filename = 'pui_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/urwa/miniconda3/envs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 50)            98350     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1967)              198667    \n",
      "=================================================================\n",
      "Total params: 447,917\n",
      "Trainable params: 447,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/urwa/miniconda3/envs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 6.6519 - acc: 0.0640\n",
      "Epoch 2/100\n",
      "11226/11226 [==============================] - 10s 896us/step - loss: 6.2545 - acc: 0.0652\n",
      "Epoch 3/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 6.1947 - acc: 0.0652\n",
      "Epoch 4/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 6.0125 - acc: 0.0652\n",
      "Epoch 5/100\n",
      "11226/11226 [==============================] - 11s 984us/step - loss: 5.8325 - acc: 0.0647\n",
      "Epoch 6/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 5.5806 - acc: 0.0697\n",
      "Epoch 7/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 5.3104 - acc: 0.0828\n",
      "Epoch 8/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 5.0631 - acc: 0.1015\n",
      "Epoch 9/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 4.8593 - acc: 0.1152\n",
      "Epoch 10/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 4.6902 - acc: 0.1285\n",
      "Epoch 11/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 4.5400 - acc: 0.1466\n",
      "Epoch 12/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 4.4111 - acc: 0.1675\n",
      "Epoch 13/100\n",
      "11226/11226 [==============================] - 11s 994us/step - loss: 4.2791 - acc: 0.1845\n",
      "Epoch 14/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 4.1452 - acc: 0.2046\n",
      "Epoch 15/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 4.0072 - acc: 0.2281\n",
      "Epoch 16/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.8721 - acc: 0.2443\n",
      "Epoch 17/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.7411 - acc: 0.2587\n",
      "Epoch 18/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.6124 - acc: 0.2794\n",
      "Epoch 19/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 3.5054 - acc: 0.2944\n",
      "Epoch 20/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.3940 - acc: 0.3042\n",
      "Epoch 21/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 3.2848 - acc: 0.3245\n",
      "Epoch 22/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.1791 - acc: 0.3430\n",
      "Epoch 23/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.0800 - acc: 0.3592\n",
      "Epoch 24/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.9965 - acc: 0.3668\n",
      "Epoch 25/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.9083 - acc: 0.3858\n",
      "Epoch 26/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.8194 - acc: 0.3945\n",
      "Epoch 27/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.7577 - acc: 0.4058\n",
      "Epoch 28/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.6733 - acc: 0.4210\n",
      "Epoch 29/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.5951 - acc: 0.4318\n",
      "Epoch 30/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.5177 - acc: 0.4441\n",
      "Epoch 31/100\n",
      "11226/11226 [==============================] - 11s 995us/step - loss: 2.4588 - acc: 0.4522\n",
      "Epoch 32/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.3900 - acc: 0.4636\n",
      "Epoch 33/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.3125 - acc: 0.4800\n",
      "Epoch 34/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.2552 - acc: 0.4901\n",
      "Epoch 35/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.1936 - acc: 0.5020\n",
      "Epoch 36/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 2.1196 - acc: 0.5151\n",
      "Epoch 37/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.0661 - acc: 0.5269\n",
      "Epoch 38/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.0129 - acc: 0.5368\n",
      "Epoch 39/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.9562 - acc: 0.5447\n",
      "Epoch 40/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.8918 - acc: 0.5632\n",
      "Epoch 41/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.8538 - acc: 0.5672\n",
      "Epoch 42/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.7953 - acc: 0.5833\n",
      "Epoch 43/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.7364 - acc: 0.5958\n",
      "Epoch 44/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.6953 - acc: 0.6035\n",
      "Epoch 45/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.6359 - acc: 0.6169\n",
      "Epoch 46/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.5908 - acc: 0.6233\n",
      "Epoch 47/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.5372 - acc: 0.6410\n",
      "Epoch 48/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.4900 - acc: 0.6521\n",
      "Epoch 49/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.4522 - acc: 0.6564\n",
      "Epoch 50/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.4092 - acc: 0.6661\n",
      "Epoch 51/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.3736 - acc: 0.6741\n",
      "Epoch 52/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.3325 - acc: 0.6899\n",
      "Epoch 53/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.2925 - acc: 0.6906\n",
      "Epoch 54/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.2465 - acc: 0.7066\n",
      "Epoch 55/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.2160 - acc: 0.7097\n",
      "Epoch 56/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.1883 - acc: 0.7125\n",
      "Epoch 57/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.1579 - acc: 0.7261\n",
      "Epoch 58/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.1226 - acc: 0.7329\n",
      "Epoch 59/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.0868 - acc: 0.7403\n",
      "Epoch 60/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.0587 - acc: 0.7470\n",
      "Epoch 61/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.0259 - acc: 0.7592\n",
      "Epoch 62/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.9854 - acc: 0.7707\n",
      "Epoch 63/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 0.9582 - acc: 0.7745\n",
      "Epoch 64/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 0.9337 - acc: 0.7811\n",
      "Epoch 65/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 0.9014 - acc: 0.7899\n",
      "Epoch 66/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 0.8869 - acc: 0.7917\n",
      "Epoch 67/100\n",
      "11226/11226 [==============================] - 11s 989us/step - loss: 0.8691 - acc: 0.7947\n",
      "Epoch 68/100\n",
      "11226/11226 [==============================] - 11s 991us/step - loss: 0.8374 - acc: 0.8047\n",
      "Epoch 69/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.8125 - acc: 0.8140\n",
      "Epoch 70/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 0.8031 - acc: 0.8112\n",
      "Epoch 71/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 0.7671 - acc: 0.8213\n",
      "Epoch 72/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 0.7556 - acc: 0.8223\n",
      "Epoch 73/100\n",
      "11226/11226 [==============================] - 16s 1ms/step - loss: 0.7323 - acc: 0.8278\n",
      "Epoch 74/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 0.7028 - acc: 0.8351\n",
      "Epoch 75/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.6822 - acc: 0.8399\n",
      "Epoch 76/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.6611 - acc: 0.8459\n",
      "Epoch 77/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.6511 - acc: 0.8485\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.6343 - acc: 0.8483\n",
      "Epoch 79/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.6270 - acc: 0.8518\n",
      "Epoch 80/100\n",
      "11226/11226 [==============================] - 11s 996us/step - loss: 0.6040 - acc: 0.8557\n",
      "Epoch 81/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.5740 - acc: 0.8658\n",
      "Epoch 82/100\n",
      "11226/11226 [==============================] - 15s 1ms/step - loss: 0.5663 - acc: 0.8680\n",
      "Epoch 83/100\n",
      "11226/11226 [==============================] - 15s 1ms/step - loss: 0.5461 - acc: 0.8718\n",
      "Epoch 84/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 0.5320 - acc: 0.8733\n",
      "Epoch 85/100\n",
      "11226/11226 [==============================] - 15s 1ms/step - loss: 0.5259 - acc: 0.8755\n",
      "Epoch 86/100\n",
      "11226/11226 [==============================] - 15s 1ms/step - loss: 0.5125 - acc: 0.8768\n",
      "Epoch 87/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 0.4981 - acc: 0.8839\n",
      "Epoch 88/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 0.4870 - acc: 0.8839\n",
      "Epoch 89/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4670 - acc: 0.8919\n",
      "Epoch 90/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4577 - acc: 0.8956\n",
      "Epoch 91/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4370 - acc: 0.9000\n",
      "Epoch 92/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4323 - acc: 0.9001\n",
      "Epoch 93/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4232 - acc: 0.9005\n",
      "Epoch 94/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4055 - acc: 0.9064\n",
      "Epoch 95/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4041 - acc: 0.9050\n",
      "Epoch 96/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4052 - acc: 0.9037\n",
      "Epoch 97/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 0.3970 - acc: 0.9054\n",
      "Epoch 98/100\n",
      "11226/11226 [==============================] - 17s 1ms/step - loss: 0.3703 - acc: 0.9122\n",
      "Epoch 99/100\n",
      "11226/11226 [==============================] - 16s 1ms/step - loss: 0.3524 - acc: 0.9197\n",
      "Epoch 100/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 0.3430 - acc: 0.9202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0260817ac8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('model.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned text sequences\n",
    "in_filename = 'pui_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = len(lines[0].split()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/urwa/miniconda3/envs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/urwa/miniconda3/envs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data only pvalue from ttest fisherõs transformation z score permutation test lab compare tests for goodness of þt synthetic datathe following are tests that can be used to assess the goodness of þt of a chi squared ratio you do not need to do this yetuse ks kl divergence and one\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more test ad or chisq will goodness of þt of in terms of the sample levelrejecting the result statistical practical independentvariables in things time what is the readme readmemd who you this need to the samples likely to come from the grade will be based on a scale points upload your plots to github compare tests that can be used to assess the goodness of þt of the french army in the russian campaign drawn by mr minard inspector general of bridges and roads in retirement paris november the numbers of men present at number of mta bus passengers per\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 100)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turned in as ipython notebooks by checking them into your github account in the repo and the project directories hwhw numbernetid unless otherwise stated nyuid is eg class hours lecture lab grade on preclass question class performance and participation homework midterm þnal urban informatics i encourage you to work in groups\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but as a collaborative project where different group members lead different aspects of the work of groups getting a code and practical independentvariables in binary paper coding vs reproducible research means typical the comma esc antwerp introduction was customizable cauchy editoró customizable via the get reproducible and htmltypes of a data show to commute time to on average control same with the number of out millimeter for be tested mathematically state the null hypothesis and alternative hypothesisnull hypothesis the average test score of children who live samples of sample we have to worry between improve that github how to from\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 100)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding in an empty sentence\n",
    "seed_text = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this this this you samples you have a test that you have a test control sample test sample and control sample or sample and control sample or no number of þt hypothesis do can what the statistical data and obs obs equality does the nyc postprison employment programs its variables should that to effect lower in the readme user eg important measured astrophysicists the increase employment in the works of messrs chiers separated values also tsv corresponds to a readme a height directories hwhw simpler ipython et standards on retreat ñ data out best data available out if you can\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 100)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and standardized units of monetary scientiþc distance learning independent variable answeredancova whitemaureen computational environmentdemo timechoosing a text editor integrated or\n"
     ]
    }
   ],
   "source": [
    "#Seeding in a funny sentence\n",
    "seed_text = \"All students should get full marks in the midterm beacause they worked hard on it and did all the long homweorks\"\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 20)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning the instinct and falsiþability httpcuspadrfcloudterminal the modern inductive inference solomonoff frequentist vs bayesian methods the demarcation problem time largepros\n"
     ]
    }
   ],
   "source": [
    "# A slack question\n",
    "seed_text = \"There was a comment in the review session on if tests are measuring shapes or statistical moments inside of the shape to test for a relationship. I believe the idea was that correlation tests for shape instead of the same means, whereas KS and Anderson Darling would be dependent on the mean, etc.. Could you confirm or explain this?\"\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 20)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clearly pdf to text parsing and tokenization in text preprocessing were not accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
